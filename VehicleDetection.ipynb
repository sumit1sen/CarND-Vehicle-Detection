{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle detection using machine learning\n",
    "Use a classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goals / steps of this project are the following:\n",
    "\n",
    "- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "- Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "- Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "- Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "- Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "- Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lesson_functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "The project comes with 2 sets of labeled data of vehicles and non-vehicles. In addition, 2 extra sets have been provided by Udacity. These have been labeled using an attacched csv file, but images are not separated into vehicle and non-vehicle folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG feature extraction\n",
    "Perform histogramming of the orientations of the gradients in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def extract_hog_features(feature_image, hog_channel, orient, pix_per_cell, cell_per_block, vis=False):\n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "    if hog_channel == 'ALL':\n",
    "        hog_features = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                orient, pix_per_cell, cell_per_block, \n",
    "                                vis=False, feature_vec=True))\n",
    "        hog_features = np.ravel(hog_features)        \n",
    "    else:\n",
    "        hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                    pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "    return hog_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine HOG, color and spatial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, cspace='RGB', hog_channel = 0, orient=9, pix_per_cell=8, cell_per_block=2, vis=False, spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        \n",
    "        # Apply HOG feature extraction\n",
    "        hog_features = extract_hog_features(feature_image, hog_channel, orient, pix_per_cell, cell_per_block, vis=False)\n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)#, bins_range=hist_range)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((hog_features, spatial_features, hist_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_ex_fullset(cars, notcars, cspace, hog_channel, orient, pix_per_cell, cell_per_block, spatial, histbin, hist_range=(0,256) ):\n",
    "    car_features = extract_features(cars, cspace, hog_channel, orient, pix_per_cell, cell_per_block, False, spatial_size=(spatial, spatial),\n",
    "                            hist_bins=histbin, hist_range=(0, 256))\n",
    "    notcar_features = extract_features(notcars, cspace,  hog_channel, orient, pix_per_cell, cell_per_block, False, spatial_size=(spatial, spatial),\n",
    "                            hist_bins=histbin, hist_range=(0, 256))\n",
    "\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "\n",
    "        # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "    print('Using spatial binning of:',spatial,\n",
    "        'and', histbin,'histogram bins')\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    return scaled_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data randomly\n",
    "For best performance, randomize the training and test data samples, taking into consideration that the raw data comes from a time series. I.e. neighboring images are very similar and highly correlated.  \n",
    "To begin with, I will use the standard sci-kit learn train_test_split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=rand_state)\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test classifier\n",
    "Add different classifiers to this section. For now, I am using a Support Vector Machine classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_SVC(X_train, y_train):\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    return svc\n",
    "\n",
    "def test_fit(classifier, cl_type, X_test, y_test):\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of ',cl_type, ' clasifier = ', round(classifier.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    n_predict = 10\n",
    "    print('My ',cl_type, ' classifier predicts: ', classifier.predict(X_test[0:n_predict]))\n",
    "    print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with ',cl_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of filenames for cars and not-cars\n",
    "# Divide up into cars and notcars\n",
    "images = glob.glob('train_images/project/vehicles/*/*.png')\n",
    "cars = []\n",
    "for image in images:\n",
    "        cars.append(image)\n",
    "\n",
    "notcars = []\n",
    "images = glob.glob('train_images/project/non-vehicles/*/*.png')\n",
    "for image in images:\n",
    "    notcars.append(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spatial binning of: 32 and 32 histogram bins\n"
     ]
    }
   ],
   "source": [
    "# TODO play with these values to see how your classifier\n",
    "# performs under different binning scenarios\n",
    "spatial = 32\n",
    "histbin = 32\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 0\n",
    "cspace='YCrCb'\n",
    "hist_range=(0,256)\n",
    "orient=9\n",
    "\n",
    "X, y = feature_ex_fullset(cars, notcars, cspace, hog_channel, orient, pix_per_cell, cell_per_block, spatial, histbin, hist_range )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 4932\n",
      "13.22 Seconds to train SVC...\n",
      "Test Accuracy of  SVC  clasifier =  0.9885\n",
      "My  SVC  classifier predicts:  [ 1.  0.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      "For these 10 labels:  [ 1.  0.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      "0.001 Seconds to predict 10 labels with  SVC\n"
     ]
    }
   ],
   "source": [
    "scaled_X = normalize(X)\n",
    "X_train, y_train, X_test, y_test = split_data(scaled_X, y)\n",
    "cl = train_SVC(X_train, y_train)\n",
    "test_fit(cl, 'SVC', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "Tune the hyperparameters of the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images/project/vehicles\\GTI_Far\\image0000.png\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window for car detection\n",
    "Detect cars at different scales in an image by using different sizes of sliding window to scan the image and detect matches to the trained classifier.\n",
    "For efficiecncy, the HOG feature extraction from the target (test) image should be calculated using sub-sampling, as shown in the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window technique\n",
    "Use a sliding window technique to search for vehicles at different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put sliding window code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG feature extraction with sub-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                \n",
    "    return draw_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test find_cars:\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1.5\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video stream\n",
    "Use a heat map of recurring detections in order to eliminate outliers and follow detected vehicles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
